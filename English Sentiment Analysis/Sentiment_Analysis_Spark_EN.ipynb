{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install pyspark nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH5H2-n77KcP",
        "outputId": "0b43e21e-ebf0-4d15-a489-e45035e9e05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (regexp_replace, col, lower, current_timestamp, when, count, size, window, round, udf)\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "from pyspark.sql.types import DoubleType\n",
        "import pandas as pd\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import os\n",
        "import glob\n",
        "from time import sleep\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "lDOrRHCf7FYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TPKd4wt7PBO",
        "outputId": "dc832f64-5087-4b80-c925-c3235e984fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to rename columns\n",
        "def rename_columns(df):\n",
        "    \"\"\"\n",
        "    Renames specific columns in the dataframe for consistency and clarity.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Input Spark DataFrame with raw column names.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Spark DataFrame with renamed columns.\n",
        "    \"\"\"\n",
        "    return df.withColumnRenamed(\"message to examine\", \"text\")\\\n",
        "             .withColumnRenamed(\"label (depression result)\", \"label\")\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(df):\n",
        "    \"\"\"\n",
        "    Performs text cleaning operations such as converting to lowercase,\n",
        "    removing URLs, mentions, hashtags, special characters, and extra spaces.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Input Spark DataFrame with text data.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Spark DataFrame with a cleaned text column.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        df.withColumn(\"cleaned_text\", lower(col(\"text\")))\n",
        "          .withColumn(\"cleaned_text\", regexp_replace(col(\"cleaned_text\"), r\"http\\S+\", \"\"))  # Remove URLs\n",
        "          .withColumn(\"cleaned_text\", regexp_replace(col(\"cleaned_text\"), r\"@\\w+\", \"\"))     # Remove mentions\n",
        "          .withColumn(\"cleaned_text\", regexp_replace(col(\"cleaned_text\"), r\"#\\w+\", \"\"))     # Remove hashtags\n",
        "          .withColumn(\"cleaned_text\", regexp_replace(col(\"cleaned_text\"), r\"[^a-zA-Z\\s]\", \"\"))  # Remove special characters\n",
        "          .withColumn(\"cleaned_text\", regexp_replace(col(\"cleaned_text\"), r\"\\s+\", \" \"))     # Remove extra spaces\n",
        "    )\n",
        "\n",
        "# Function to preprocess text: Tokenization and stop word removal\n",
        "def preprocess_text(df):\n",
        "    \"\"\"\n",
        "    Tokenizes the cleaned text and removes stop words. Filters out rows\n",
        "    with empty token lists.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Input Spark DataFrame with cleaned text.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Spark DataFrame with tokens and filtered tokens.\n",
        "    \"\"\"\n",
        "    tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"tokens\")\n",
        "    stop_words_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
        "\n",
        "    # Apply transformations\n",
        "    df_tokenized = tokenizer.transform(df)\n",
        "    df_filtered = stop_words_remover.transform(df_tokenized)\n",
        "\n",
        "    # Remove rows with empty tokens\n",
        "    return df_filtered.filter(size(col(\"filtered_tokens\")) > 0)\n",
        "\n",
        "# Define the VADER sentiment analysis UDF\n",
        "def analyze_sentiment_vader(text):\n",
        "    \"\"\"\n",
        "    Performs sentiment analysis using the VADER lexicon. Calculates a compound\n",
        "    score and classifies the sentiment as positive (1.0) or negative (0.0).\n",
        "\n",
        "    Args:\n",
        "        text (str or list): Input text or tokenized list of words.\n",
        "\n",
        "    Returns:\n",
        "        float: Sentiment classification, where 1.0 is positive and 0.0 is negative.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return 0  # if text is empty\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    sentiment_scores = sid.polarity_scores(' '.join(text) if isinstance(text, list) else text)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "    return 1.0 if compound_score < -0.25 else 0.0 # Threshold is set to -0.25\n",
        "\n",
        "# Register UDF for Spark\n",
        "vader_sentiment_udf = udf(analyze_sentiment_vader, DoubleType())\n",
        "\n",
        "# Load and preprocess data\n",
        "def process_batch_data(file_path):\n",
        "    \"\"\"\n",
        "    Loads the data from a CSV file, renames columns, and performs cleaning\n",
        "    and preprocessing.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the input CSV file.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Processed Spark DataFrame ready for sentiment analysis.\n",
        "    \"\"\"\n",
        "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "    df = rename_columns(df)\n",
        "    df = clean_text(df)\n",
        "    df = preprocess_text(df)\n",
        "    return df\n",
        "\n",
        "# Sentiment analysis and evaluation\n",
        "def apply_vader_sentiment(df):\n",
        "    \"\"\"\n",
        "    Applies the VADER sentiment analysis UDF to classify text sentiment.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Spark DataFrame with filtered tokens.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Spark DataFrame with an additional column for predicted sentiment.\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"vader_predicted_label\", vader_sentiment_udf(col(\"filtered_tokens\")))"
      ],
      "metadata": {
        "id": "LxjZR8VH-P7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main analysis process\n",
        "file_path = \"/content/sentiment_tweets3.csv\"\n",
        "df_processed = process_batch_data(file_path)\n",
        "df_with_vader = apply_vader_sentiment(df_processed)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (\n",
        "    df_with_vader.filter(df_with_vader.vader_predicted_label == df_with_vader.label).count() /\n",
        "    df_with_vader.count()\n",
        ")\n",
        "print(f\"VADER Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gJtqfoK-VBD",
        "outputId": "ca6d7264-47bb-4837-e30e-804fdd123752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER Accuracy: 87.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time plotting function\n",
        "def plot_sentiment_analysis(aggregated_data):\n",
        "    \"\"\"\n",
        "    Generates and updates a real-time Plotly chart to display sentiment analysis results.\n",
        "\n",
        "    Args:\n",
        "        aggregated_data (list): List of dictionaries containing sentiment percentages\n",
        "                                and timestamps for visualization.\n",
        "    \"\"\"\n",
        "    plot_times, positive_percentages, negative_percentages = [], [], []\n",
        "    fig = make_subplots(rows=1, cols=1)\n",
        "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines+markers', name='Positive Sentiment (%)', line=dict(color='green')))\n",
        "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines+markers', name='Negative Sentiment (%)', line=dict(color='red')))\n",
        "    fig.update_layout(title='Sentiment Analysis Over Time', xaxis_title='Time', yaxis_title='Sentiment Percentage', template='plotly_white')\n",
        "\n",
        "    for entry in aggregated_data:\n",
        "        plot_times.append(entry['time'])\n",
        "        positive_percentages.append(entry['positive_percentage'])\n",
        "        negative_percentages.append(entry['negative_percentage'])\n",
        "\n",
        "        fig.data[0].x = plot_times\n",
        "        fig.data[0].y = positive_percentages\n",
        "        fig.data[1].x = plot_times\n",
        "        fig.data[1].y = negative_percentages\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        display(fig)"
      ],
      "metadata": {
        "id": "Edg5zpApBQ0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated streaming processing (5 minutes interval)\n",
        "def simulated_streaming_processing(data, chunk_size, output_path, window_size=\"1 minutes\", toPlot=True, toAggregate=False):\n",
        "    \"\"\"\n",
        "    Processes data in a simulated streaming fashion. Aggregates sentiment analysis\n",
        "    results in time windows and optionally generates real-time plots.\n",
        "\n",
        "    Args:\n",
        "        data (DataFrame): Pandas DataFrame containing input data.\n",
        "        chunk_size (int): Number of rows to process per chunk.\n",
        "        output_path (str): Path to store aggregated results as a CSV file.\n",
        "        window_size (str): Time window size for aggregation.\n",
        "        toPlot (bool): If True, plots results in real-time.\n",
        "        toAggregate (bool): If True, displays aggregated results.\n",
        "    \"\"\"\n",
        "    start_time = pd.to_datetime(\"2024-11-30 20:20:00\")\n",
        "    end_time = start_time + pd.Timedelta(minutes=1)\n",
        "    aggregated_results = []\n",
        "\n",
        "    for i in range(0, len(data), chunk_size):\n",
        "        # Extract chunk\n",
        "        chunk = data.iloc[i:i + chunk_size]\n",
        "        chunk['timestamp'] = start_time\n",
        "        start_time = end_time\n",
        "        end_time = start_time + pd.Timedelta(minutes=1)\n",
        "\n",
        "        # Process data chunk\n",
        "        chunk_spark = spark.createDataFrame(chunk)\n",
        "        chunk_spark = rename_columns(chunk_spark)\n",
        "        chunk_spark = clean_text(chunk_spark)\n",
        "        chunk_spark = preprocess_text(chunk_spark)\n",
        "\n",
        "        # Apply sentiment analysis\n",
        "        df_with_vader = apply_vader_sentiment(chunk_spark)\n",
        "        df_with_vader = df_with_vader.withColumn(\"processing_time\", current_timestamp())\n",
        "\n",
        "        # Aggregate in 5-minute windows\n",
        "        df_aggregated = (\n",
        "            df_with_vader\n",
        "            .groupBy(window(col(\"processing_time\"), window_size))\n",
        "            .agg(\n",
        "                count(when(col(\"vader_predicted_label\") == 1.0, True)).alias(\"positive_count\"),\n",
        "                count(when(col(\"vader_predicted_label\") == 0.0, True)).alias(\"negative_count\"),\n",
        "                count(\"*\").alias(\"total_count\")\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Calculate percentages\n",
        "        df_aggregated_with_percentages = df_aggregated.withColumn(\n",
        "            \"positive_percentage\", round((col(\"positive_count\") / col(\"total_count\")) * 100, 1)\n",
        "        ).withColumn(\n",
        "            \"negative_percentage\", round((col(\"negative_count\") / col(\"total_count\")) * 100, 1)\n",
        "        )\n",
        "\n",
        "        df_aggregated_with_times = df_aggregated_with_percentages.select(\n",
        "            \"window.start\", \"window.end\", \"positive_count\", \"negative_count\",\n",
        "            \"total_count\", \"positive_percentage\", \"negative_percentage\"\n",
        "        )\n",
        "\n",
        "        # Convert to Pandas DataFrame for storage or visualization\n",
        "        pandas_df = df_aggregated_with_times.toPandas()\n",
        "\n",
        "        if os.path.exists(output_path):\n",
        "            pandas_df.to_csv(output_path, mode='a', header=False, index=False)\n",
        "        else:\n",
        "            pandas_df.to_csv(output_path, mode='w', header=True, index=False)\n",
        "\n",
        "        # Append results for plotting\n",
        "        for _, row in pandas_df.iterrows():\n",
        "            aggregated_results.append({\n",
        "                'time': row['start'],\n",
        "                'positive_percentage': row['positive_percentage'],\n",
        "                'negative_percentage': row['negative_percentage']\n",
        "            })\n",
        "\n",
        "        # Whether to plot or aggregate (one at a time, since we're using cloud-based notebook)\n",
        "        if toAggregate:\n",
        "          df_aggregated_with_percentages.show(truncate=False)\n",
        "        elif toPlot:\n",
        "          plot_sentiment_analysis(aggregated_results)\n",
        "\n",
        "        # Delay of 5 minutes to simulate real-time\n",
        "        sleep(60)\n",
        "\n",
        "def clean_output_folder(output_folder):\n",
        "    \"\"\"\n",
        "    Cleans the output folder by removing all files.\n",
        "\n",
        "    Args:\n",
        "        output_folder (str): Path to the folder to be cleaned.\n",
        "    \"\"\"\n",
        "    files = glob.glob(f\"{output_folder}/*\")\n",
        "    for file in files:\n",
        "        os.remove(file)\n",
        "        print(f\"Deleted {file}\")"
      ],
      "metadata": {
        "id": "AA9D1cfM-rP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_output_folder(\"output\")\n",
        "data = pd.read_csv(file_path)\n",
        "output_path = \"output/sentiment_results.csv\"\n",
        "# Aggregate the streaming data results\n",
        "simulated_streaming_processing(data, chunk_size=100, output_path=output_path, toPlot=False, toAggregate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "oG2fAB8--vts",
        "outputId": "d3bcc2de-8926-4c25-9a21-5cdcd0fade5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cebf3473014c>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk['timestamp'] = start_time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|window                                    |positive_count|negative_count|total_count|positive_percentage|negative_percentage|\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|{2024-12-01 19:25:00, 2024-12-01 19:26:00}|6             |93            |99         |6.1                |93.9               |\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cebf3473014c>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk['timestamp'] = start_time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|window                                    |positive_count|negative_count|total_count|positive_percentage|negative_percentage|\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|{2024-12-01 19:26:00, 2024-12-01 19:27:00}|6             |93            |99         |6.1                |93.9               |\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-cebf3473014c>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  chunk['timestamp'] = start_time\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|window                                    |positive_count|negative_count|total_count|positive_percentage|negative_percentage|\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "|{2024-12-01 19:27:00, 2024-12-01 19:28:00}|5             |94            |99         |5.1                |94.9               |\n",
            "+------------------------------------------+--------------+--------------+-----------+-------------------+-------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-79c9fc893a04>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output/sentiment_results.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Aggregate the streaming data results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msimulated_streaming_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoPlot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoAggregate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-cebf3473014c>\u001b[0m in \u001b[0;36msimulated_streaming_processing\u001b[0;34m(data, chunk_size, output_path, window_size, toPlot, toAggregate)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Delay of 5 minutes to simulate real-time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_output_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_output_folder(\"output\")\n",
        "data = pd.read_csv(file_path)\n",
        "output_path = \"output/sentiment_results.csv\"\n",
        "# Plot the streaming data results\n",
        "simulated_streaming_processing(data, chunk_size=100, output_path=output_path, toPlot=True, toAggregate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "IDUM5gbWKE_L",
        "outputId": "ce1e21e3-f172-4e27-c6c0-89c516f8400c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4dc2f339-2315-4bdd-bf1d-aaf93fc0262a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4dc2f339-2315-4bdd-bf1d-aaf93fc0262a\")) {                    Plotly.newPlot(                        \"4dc2f339-2315-4bdd-bf1d-aaf93fc0262a\",                        [{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Positive Sentiment (%)\",\"x\":[\"2024-12-01T19:27:00\",\"2024-12-01T19:28:00\",\"2024-12-01T19:29:00\",\"2024-12-01T19:30:00\"],\"y\":[6.1,6.1,5.1,7.0],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Negative Sentiment (%)\",\"x\":[\"2024-12-01T19:27:00\",\"2024-12-01T19:28:00\",\"2024-12-01T19:29:00\",\"2024-12-01T19:30:00\"],\"y\":[93.9,93.9,94.9,93.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Sentiment Percentage\"}},\"title\":{\"text\":\"Sentiment Analysis Over Time\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4dc2f339-2315-4bdd-bf1d-aaf93fc0262a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-400262816824>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output/sentiment_results.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the streaming data results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msimulated_streaming_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoPlot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoAggregate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-cebf3473014c>\u001b[0m in \u001b[0;36msimulated_streaming_processing\u001b[0;34m(data, chunk_size, output_path, window_size, toPlot, toAggregate)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Delay of 5 minutes to simulate real-time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_output_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "iCis20Fi_neO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXGs3aOutKeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}